{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e213b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.datasets import load_gunpoint\n",
    "from pyts.image import GramianAngularField\n",
    "#from pyts.image import GASF, GADF\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.misc import electrocardiogram\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from pyts.image import MarkovTransitionField\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('sci/농도별데이터_2022/TNT/10ng/TNT_10.csv')\n",
    "#data_frame = pd.read_csv('sci/농도별데이터_2022/Normal/Normal_10.csv')\n",
    "print(data_frame)\n",
    "graph_data_or = data_frame['ims']\n",
    "graph_data_sum=0\n",
    "graph_data_sum_last=[]\n",
    "cnt_first_graph=1\n",
    "graph_first_preview = []\n",
    "\n",
    "graph_first_preview = data_frame[0:1000]\n",
    "plt.plot(graph_first_preview)\n",
    "'''\n",
    "for i in range(math.ceil(len(graph_data_or))):\n",
    "    graph_data_sum = graph_data_sum + sum(graph_data_or[i:i+50])#값 모두다 합침\n",
    "    graph_data_sum_last = np.append(graph_data_sum_last, int(math.ceil(graph_data_sum/50)))\n",
    "    # 50번째마다 데이터 들의 합의 평균을 저장\n",
    "    #print(len(graph_data_sum_last))\n",
    "    graph_data_sum = 0\n",
    "    cnt_first_graph = cnt_first_graph + 1\n",
    "'''\n",
    "for i in range(math.ceil(len(graph_data_or))):\n",
    "    graph_data_sum = graph_data_sum + graph_data_or[i]\n",
    "    if cnt_first_graph%20==0:\n",
    "        graph_data_sum_last = np.append(graph_data_sum_last, graph_data_sum)\n",
    "        graph_data_sum = 0\n",
    "    cnt_first_graph = cnt_first_graph + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7933b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(graph_data_sum_last)\n",
    "#df_1.to_csv('peak_con/rdx/200n/RDX_200ng.csv', encoding='utf-8', index=False)\n",
    "df_1.to_csv('sci/tnt_10_10ng.csv', encoding='utf-8', index=False)\n",
    "#df_1.to_csv('sci/Normal_10.csv', encoding='utf-8', index=False)\n",
    "print(len(graph_data_sum_last))\n",
    "graph_data_sum_last_review = graph_data_sum_last[0:60]\n",
    "plt.plot(graph_data_sum_last_review)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_3 = pd.read_csv(\"peak_con/tnt/200n/TNT_200ng.csv\")\n",
    "df_3 = pd.read_csv(\"sci/ng_10_200ng.csv\")\n",
    "#df_3 = pd.read_csv(\"sci/Normal_10.csv\")\n",
    "df_3 = df_3['0']\n",
    "\n",
    "#print(math.ceil(len(df_3)/4455)-1)\n",
    "#print(math.ceil(len(df_3)/15)-1)\n",
    "graph_num=[]\n",
    "peak_num_count=[]\n",
    "sum_where_min_peak=[]\n",
    "a = []\n",
    "b = []\n",
    "#for i in range(math.ceil(len(df_3)/60)-1):\n",
    "for i in range(math.ceil(len(df_3)/30)-1):\n",
    "#for i in range(5):\n",
    "    #graph_num = df_3[(i*4455):((i+1)*4455)]\n",
    "    #graph_num = df_3[(i*15):((i+1)*15)]\n",
    "    graph_num = df_3[(i*30):((i+1)*30)]\n",
    "    #print(graph_num)\n",
    "    \n",
    "    peaks, properties = find_peaks(graph_num, height=(None, -4000000))\n",
    "    peaks_num = peaks # 피크의 위치들\n",
    "    peaks_value = properties[\"peak_heights\"] # 피크의 위치들의 값\n",
    "    print(peaks_value)\n",
    "    \n",
    "    try:\n",
    "        max_peak_value = max(peaks_value) # 피크의 값중 가장 값\n",
    "        #max_peak_find = np.where(peaks_value==max_peak_value) # 탐색 된 가장 작은 피크값의 위치 값\n",
    "    except ValueError:\n",
    "        max_peak_value = -200000000\n",
    "    max_peak_find = np.where(peaks_value==max_peak_value) # 탐색 된 가장 작은 피크값의 위치 값\n",
    "    where_max_peak = peaks_num[max_peak_find] #가장 작은 피크값들 위치 모음\n",
    "    \n",
    "    if i > 0:\n",
    "        #sum_where_min_peak = where_min_peak + sum_where_min_peak # 가장 작은 \n",
    "        sum_where_max_peak = where_max_peak\n",
    "        a= np.array(sum_where_max_peak)\n",
    "    else:\n",
    "        sum_where_max_peak = where_max_peak\n",
    "        a= np.array(sum_where_max_peak)\n",
    "    \n",
    "    #a= np.array(where_min_peak) #peak값 위치모음 numpy배열에 저장\n",
    "    #print(a)\n",
    "    #b= np.array(i*4455) #peak 위치값의 정확한 위치를 파악하기 위해 더해주는 값\n",
    "    b= np.array(i*30)\n",
    "    #print(b)\n",
    "        \n",
    "    peak_num_count = np.append(peak_num_count,a+b) #작은 피크들 위치 값 배열에 저장\n",
    "    #print(peak_num_count)\n",
    "    graph_num.plot(alpha = 0.5)\n",
    "    plt.scatter((i*30)+peaks_num[max_peak_find], max_peak_value, c = 'r') # 피크들 그래프 상에 점의 형식으로 띄우는 것\n",
    "    \n",
    "#print(peak_num_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_frame_Cut_main = pd.read_csv(\"peak_con/tnt/200n/TNT_200ng.csv\")\n",
    "data_frame_Cut_main = pd.read_csv(\"sci/ng_10_200ng.csv\")\n",
    "#data_frame_Cut_main = pd.read_csv(\"sci/Normal_10.csv\")\n",
    "#print(data_frame_Cut_main)\n",
    "\n",
    "cnt = 1\n",
    "nsample = 0\n",
    "Cut_data_main = data_frame_Cut_main[['0']]\n",
    "\n",
    "peak_num_count_=[]\n",
    "for c in range(len(peak_num_count)):\n",
    "    peak_num_count_.append(int(peak_num_count[c]))\n",
    "    #print(peak_num_count_)\n",
    "peak_num_count_.append(0)\n",
    "#for c in range(math.ceil(len(Cut_data_main)/4455)-1):\n",
    "#for c in range(math.ceil(len(Cut_data_main)/15)-1):\n",
    "for c in range(math.ceil(len(Cut_data_main)/30)-1):\n",
    "    nc1 = peak_num_count_[c-1]\n",
    "    nc2 = peak_num_count_[c]\n",
    "    if nc1 != nc2:\n",
    "        gg = Cut_data_main[nc1:nc2]\n",
    "        gg_=np.array(gg)\n",
    "        save_data=pd.DataFrame(gg_)\n",
    "        #save_data.to_csv('peak_con/tnt/200n/csv/TNT_200ng_%d.csv'% (cnt), encoding='utf-8', index=False)\n",
    "        save_data.to_csv('sci/농도별데이터_2022/NG/200ng/200_10/NG_200ng_10_%d.csv'% (cnt), encoding='utf-8', index=False)\n",
    "        #save_data.to_csv('sci/농도별데이터_2022/Normal/10_10/Normal_10_%d.csv'% (cnt), encoding='utf-8', index=False)\n",
    "        plt.plot(gg)\n",
    "        plt.suptitle(cnt, y=0.98, fontsize=16)\n",
    "        plt.show()\n",
    "        ''' \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler_fit = scaler.fit(gg)\n",
    "        scaler_data = scaler.transform(gg)\n",
    "        \n",
    "        \n",
    "        gasf = GramianAngularField(image_size=1, method='summation')\n",
    "        X_gasf = gasf.fit_transform(gg_new)\n",
    "        print(X_gasf)\n",
    "        gadf = GramianAngularField(image_size=1, method='difference')\n",
    "        X_gadf = gadf.fit_transform(gg_new)\n",
    "        \n",
    "        gaf = GramianAngularField(image_size=1)\n",
    "        \n",
    "        im_gg = gaf.fit_transform(scaler_data)\n",
    "        print(im_gg)\n",
    "        plt.imshow(im_gg[0])\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "        #plt.imshow(gg_1)\n",
    "        #plt.savefig('Concentration_IMS/RDX_10ng/RDX_10ng_%d.png'% (c))\n",
    "        cnt = cnt + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
